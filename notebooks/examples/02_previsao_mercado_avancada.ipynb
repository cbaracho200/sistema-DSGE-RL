{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Previs\u00e3o Avan\u00e7ada de Mercado Imobili\u00e1rio - IDCI-VIX\n",
    "\n",
    "Este notebook demonstra uma aplica\u00e7\u00e3o avan\u00e7ada do sistema de previs\u00e3o usando:\n",
    "\n",
    "- Constru\u00e7\u00e3o do \u00cdndice Din\u00e2mico de Confian\u00e7a Imobili\u00e1ria (IDCI-VIX)\n",
    "- Sele\u00e7\u00e3o autom\u00e1tica de vari\u00e1veis via causalidade de Granger\n",
    "- M\u00faltiplos modelos de previs\u00e3o (ARIMA, SARIMA, Markov-Switching, ML)\n",
    "- Ensemble learning otimizado\n",
    "- Valida\u00e7\u00e3o temporal com cross-validation\n",
    "- An\u00e1lise de performance e diagn\u00f3sticos completos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Adicionar o diret\u00f3rio src ao path\n",
    "sys.path.insert(0, os.path.abspath('../../src'))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configurar estilo de visualiza\u00e7\u00e3o\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Gera\u00e7\u00e3o de Dados Sint\u00e9ticos Realistas\n",
    "\n",
    "Vamos criar um dataset sint\u00e9tico que simula vari\u00e1veis macroecon\u00f4micas reais:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gerar_dados_realistas(n_periodos=120, seed=42):\n",
    "    \"\"\"\n",
    "    Gera dados sint\u00e9ticos realistas simulando vari\u00e1veis macroecon\u00f4micas.\n",
    "    \n",
    "    Vari\u00e1veis inclu\u00eddas:\n",
    "    - PIB: Tend\u00eancia crescente com ciclos\n",
    "    - Taxa Selic: Pol\u00edtica monet\u00e1ria com mudan\u00e7as de regime\n",
    "    - IPCA: Infla\u00e7\u00e3o com persist\u00eancia\n",
    "    - Desemprego: Contra-c\u00edclico ao PIB\n",
    "    - Cr\u00e9dito Imobili\u00e1rio: Relacionado ao PIB e Selic\n",
    "    - Vendas Varejo: Indicador de consumo\n",
    "    - Confian\u00e7a do Consumidor: Sentimento de mercado\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Datas mensais\n",
    "    datas = pd.date_range(start='2015-01-01', periods=n_periodos, freq='M')\n",
    "    \n",
    "    # Tend\u00eancia temporal\n",
    "    t = np.arange(n_periodos)\n",
    "    \n",
    "    # PIB - Crescimento com ciclos econ\u00f4micos\n",
    "    pib_tendencia = 2000 + 15 * t\n",
    "    pib_ciclo = 200 * np.sin(2 * np.pi * t / 48) + 100 * np.sin(2 * np.pi * t / 24)\n",
    "    pib = pib_tendencia + pib_ciclo + np.random.normal(0, 50, n_periodos)\n",
    "    \n",
    "    # Selic - Pol\u00edtica monet\u00e1ria reativa \u00e0 infla\u00e7\u00e3o\n",
    "    selic_base = 10.0\n",
    "    selic = np.zeros(n_periodos)\n",
    "    selic[0] = selic_base\n",
    "    for i in range(1, n_periodos):\n",
    "        shock = np.random.normal(0, 0.3)\n",
    "        # Mudan\u00e7as de regime ocasionais\n",
    "        if i % 30 == 0:\n",
    "            shock += np.random.choice([-2, 2])\n",
    "        selic[i] = np.clip(selic[i-1] + shock, 2.0, 20.0)\n",
    "    \n",
    "    # IPCA - Infla\u00e7\u00e3o com persist\u00eancia\n",
    "    ipca = np.zeros(n_periodos)\n",
    "    ipca[0] = 0.5\n",
    "    for i in range(1, n_periodos):\n",
    "        # AR(1) com m\u00e9dia m\u00f3vel\n",
    "        ipca[i] = 0.6 * ipca[i-1] + 0.3 + np.random.normal(0, 0.2)\n",
    "        ipca[i] = np.clip(ipca[i], -1.0, 2.5)\n",
    "    \n",
    "    # Desemprego - Contra-c\u00edclico\n",
    "    desemprego_base = 10.0\n",
    "    pib_normalizado = (pib - pib.mean()) / pib.std()\n",
    "    desemprego = desemprego_base - 2 * pib_normalizado + np.random.normal(0, 0.5, n_periodos)\n",
    "    desemprego = np.clip(desemprego, 4.0, 16.0)\n",
    "    \n",
    "    # Cr\u00e9dito Imobili\u00e1rio - Positivo com PIB, negativo com Selic\n",
    "    credito_tendencia = 50000 + 400 * t\n",
    "    credito_ciclo = 5000 * pib_normalizado - 2000 * (selic - selic.mean()) / selic.std()\n",
    "    credito = credito_tendencia + credito_ciclo + np.random.normal(0, 2000, n_periodos)\n",
    "    \n",
    "    # Vendas Varejo - Relacionado ao PIB e confian\u00e7a\n",
    "    vendas_base = 100\n",
    "    vendas = vendas_base + 10 * np.sin(2 * np.pi * t / 12) + 5 * pib_normalizado\n",
    "    vendas += np.random.normal(0, 3, n_periodos)\n",
    "    \n",
    "    # Confian\u00e7a do Consumidor - Sentimento geral\n",
    "    confianca = 100 + 15 * pib_normalizado - 10 * (desemprego - desemprego.mean()) / desemprego.std()\n",
    "    confianca += np.random.normal(0, 5, n_periodos)\n",
    "    \n",
    "    # Criar DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'data': datas,\n",
    "        'pib_real': pib,\n",
    "        'taxa_selic': selic,\n",
    "        'ipca': ipca,\n",
    "        'taxa_desemprego': desemprego,\n",
    "        'credito_imobiliario': credito,\n",
    "        'vendas_varejo': vendas,\n",
    "        'confianca_consumidor': confianca\n",
    "    })\n",
    "    \n",
    "    df.set_index('data', inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Gerar dados\n",
    "df = gerar_dados_realistas(n_periodos=120)\n",
    "print(\"Dataset gerado:\")\n",
    "print(f\"Per\u00edodo: {df.index[0].strftime('%Y-%m')} a {df.index[-1].strftime('%Y-%m')}\")\n",
    "print(f\"Observa\u00e7\u00f5es: {len(df)}\")\n",
    "print(f\"\\nPrimeiras linhas:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. An\u00e1lise Explorat\u00f3ria dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estat\u00edsticas descritivas\n",
    "print(\"Estat\u00edsticas Descritivas:\")\n",
    "print(\"=\" * 80)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar s\u00e9ries temporais\n",
    "fig, axes = plt.subplots(4, 2, figsize=(16, 14))\n",
    "fig.suptitle('S\u00e9ries Temporais das Vari\u00e1veis Macroecon\u00f4micas', fontsize=16, fontweight='bold')\n",
    "\n",
    "for idx, col in enumerate(df.columns):\n",
    "    ax = axes[idx // 2, idx % 2]\n",
    "    ax.plot(df.index, df[col], linewidth=2)\n",
    "    ax.set_title(col.replace('_', ' ').title(), fontsize=12, fontweight='bold')\n",
    "    ax.set_xlabel('Data', fontsize=10)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de correla\u00e7\u00e3o\n",
    "plt.figure(figsize=(12, 10))\n",
    "correlation_matrix = df.corr()\n",
    "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "sns.heatmap(correlation_matrix, mask=mask, annot=True, fmt='.2f', \n",
    "            cmap='coolwarm', center=0, square=True, linewidths=1,\n",
    "            cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Matriz de Correla\u00e7\u00e3o das Vari\u00e1veis', fontsize=14, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Testes de Estacionaridade e Transforma\u00e7\u00f5es\n",
    "\n",
    "Aplicar testes ADF e KPSS para determinar se as s\u00e9ries precisam de diferencia\u00e7\u00e3o:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing.stationarity import StationarityTester",
    "",
    "# Testar estacionaridade",
    "tester = StationarityTester(alpha=0.05)",
    "",
    "print(\"Testes de Estacionaridade (ADF e KPSS)\")",
    "print(\"=\" * 80)",
    "",
    "resultados_estacionaridade = {}",
    "for col in df.columns:",
    "    result = tester.test_stationarity(df[col])",
    "    ",
    "    is_stationary = result['is_stationary']",
    "    adf_pval = result['adf']['pvalue']",
    "    kpss_pval = result['kpss']['pvalue']",
    "    ",
    "    resultados_estacionaridade[col] = {",
    "        'estacionaria': is_stationary,",
    "        'adf_pvalue': adf_pval,",
    "        'kpss_pvalue': kpss_pval",
    "    }",
    "    ",
    "    status = \"\u2713 Estacion\u00e1ria\" if is_stationary else \"\u2717 N\u00e3o estacion\u00e1ria\"",
    "    print(f\"{col:25s} {status:20s} | ADF p={adf_pval:.4f} | KPSS p={kpss_pval:.4f}\")",
    "",
    "print(\"",
    "\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar transforma\u00e7\u00f5es para tornar s\u00e9ries estacion\u00e1rias\n",
    "df_transformed = df.copy()\n",
    "transformacoes = {}\n",
    "\n",
    "for col in df.columns:\n",
    "    if not resultados_estacionaridade[col]['estacionaria']:\n",
    "        # Aplicar primeira diferen\u00e7a\n",
    "        df_transformed[col] = df[col].diff()\n",
    "        transformacoes[col] = 'diff(1)'\n",
    "    else:\n",
    "        transformacoes[col] = 'none'\n",
    "\n",
    "# Remover NaNs gerados pela diferencia\u00e7\u00e3o\n",
    "df_transformed = df_transformed.dropna()\n",
    "\n",
    "print(\"Transforma\u00e7\u00f5es aplicadas:\")\n",
    "for col, trans in transformacoes.items():\n",
    "    print(f\"  {col:25s} -> {trans}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Sele\u00e7\u00e3o de Vari\u00e1veis via Causalidade de Granger\n",
    "\n",
    "Identificar quais vari\u00e1veis t\u00eam poder preditivo para o PIB:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing.variable_selection import GrangerSelector\n",
    "\n",
    "# Selecionar vari\u00e1veis que causam Granger no PIB\n",
    "target = 'pib_real'\n",
    "selector = GrangerSelector(max_lag=6, alpha=0.05)\n",
    "\n",
    "selected_vars = selector.select_variables(\n",
    "    df_transformed,\n",
    "    target_col=target\n",
    ")\n",
    "\n",
    "print(f\"\\nVari\u00e1veis selecionadas (Granger-causam '{target}'):\")\n",
    "print(\"=\" * 80)\n",
    "for var in selected_vars:\n",
    "    if var != target:\n",
    "        print(f\"  \u2713 {var}\")\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Constru\u00e7\u00e3o do \u00cdndice IDCI-VIX via Modelo de Fatores Din\u00e2micos\n",
    "\n",
    "Usar Filtro de Kalman para extrair um fator latente comum:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from factor_model.dynamic_factor import DynamicFactorModel\n",
    "\n",
    "# Preparar dados para o modelo de fatores\n",
    "X_factor = df_transformed[selected_vars].values\n",
    "\n",
    "# Estimar modelo de fator din\u00e2mico\n",
    "dfm = DynamicFactorModel(n_factors=1)\n",
    "dfm.fit(X_factor)\n",
    "\n",
    "# Extrair fator (IDCI-VIX bruto)\n",
    "factor_raw = dfm.factors_.flatten()\n",
    "\n",
    "# Normalizar para escala 0-10\n",
    "factor_min = factor_raw.min()\n",
    "factor_max = factor_raw.max()\n",
    "idci_vix = 10 * (factor_raw - factor_min) / (factor_max - factor_min)\n",
    "\n",
    "# Adicionar ao DataFrame\n",
    "df_transformed['IDCI_VIX'] = idci_vix\n",
    "\n",
    "print(f\"\u00cdndice IDCI-VIX constru\u00eddo:\")\n",
    "print(f\"  M\u00e9dia: {idci_vix.mean():.2f}\")\n",
    "print(f\"  Desvio: {idci_vix.std():.2f}\")\n",
    "print(f\"  M\u00edn/M\u00e1x: {idci_vix.min():.2f} / {idci_vix.max():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar IDCI-VIX\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "ax.plot(df_transformed.index, idci_vix, linewidth=2.5, color='darkblue', label='IDCI-VIX')\n",
    "ax.axhline(y=5, color='red', linestyle='--', alpha=0.5, label='Mediana (5.0)')\n",
    "ax.fill_between(df_transformed.index, 0, 10, alpha=0.1, color='blue')\n",
    "ax.set_title('\u00cdndice Din\u00e2mico de Confian\u00e7a Imobili\u00e1ria - Vit\u00f3ria (IDCI-VIX)', \n",
    "             fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Data', fontsize=12)\n",
    "ax.set_ylabel('\u00cdndice (0-10)', fontsize=12)\n",
    "ax.set_ylim(0, 10)\n",
    "ax.legend(loc='best')\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Modelagem e Previs\u00e3o com M\u00faltiplos Modelos\n",
    "\n",
    "Treinar v\u00e1rios modelos e comparar performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from forecasting.arima import ARIMAForecaster\n",
    "from forecasting.sarima import SARIMAForecaster\n",
    "from forecasting.markov_switching import MarkovSwitchingForecaster\n",
    "from forecasting.ridge import RidgeForecaster\n",
    "from forecasting.random_forest import RandomForestForecaster\n",
    "\n",
    "# Dividir dados: 80% treino, 20% teste\n",
    "train_size = int(0.8 * len(df_transformed))\n",
    "train_data = df_transformed.iloc[:train_size]\n",
    "test_data = df_transformed.iloc[train_size:]\n",
    "\n",
    "target_col = 'IDCI_VIX'\n",
    "y_train = train_data[target_col].values\n",
    "y_test = test_data[target_col].values\n",
    "n_forecast = len(y_test)\n",
    "\n",
    "print(f\"Tamanho do conjunto de treino: {len(train_data)}\")\n",
    "print(f\"Tamanho do conjunto de teste: {len(test_data)}\")\n",
    "print(f\"Horizonte de previs\u00e3o: {n_forecast} per\u00edodos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dicion\u00e1rio para armazenar previs\u00f5es\n",
    "previsoes = {}\n",
    "\n",
    "# 1. ARIMA\n",
    "print(\"Treinando ARIMA...\")\n",
    "arima = ARIMAForecaster(order=(2, 0, 2))\n",
    "arima.fit(y_train)\n",
    "previsoes['ARIMA'] = arima.forecast(n_forecast)\n",
    "\n",
    "# 2. SARIMA\n",
    "print(\"Treinando SARIMA...\")\n",
    "sarima = SARIMAForecaster(order=(1, 0, 1), seasonal_order=(1, 0, 1, 12))\n",
    "sarima.fit(y_train)\n",
    "previsoes['SARIMA'] = sarima.forecast(n_forecast)\n",
    "\n",
    "# 3. Markov-Switching\n",
    "print(\"Treinando Markov-Switching...\")\n",
    "ms = MarkovSwitchingForecaster(n_regimes=2, order=2)\n",
    "ms.fit(y_train)\n",
    "previsoes['Markov-Switching'] = ms.forecast(n_forecast)\n",
    "\n",
    "# 4. Ridge Regression\n",
    "print(\"Treinando Ridge...\")\n",
    "X_train = train_data[selected_vars].values\n",
    "X_test = test_data[selected_vars].values\n",
    "ridge = RidgeForecaster(alpha=1.0, lags=3)\n",
    "ridge.fit(X_train, y_train)\n",
    "previsoes['Ridge'] = ridge.forecast(X_test)\n",
    "\n",
    "# 5. Random Forest\n",
    "print(\"Treinando Random Forest...\")\n",
    "rf = RandomForestForecaster(n_estimators=100, max_depth=10, lags=5)\n",
    "rf.fit(X_train, y_train)\n",
    "previsoes['Random Forest'] = rf.forecast(X_test)\n",
    "\n",
    "print(\"\\n\u2713 Todos os modelos treinados com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Avalia\u00e7\u00e3o e Compara\u00e7\u00e3o de Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation.metrics import calculate_metrics\n",
    "\n",
    "# Calcular m\u00e9tricas para cada modelo\n",
    "metricas_modelos = {}\n",
    "\n",
    "for nome_modelo, y_pred in previsoes.items():\n",
    "    metrics = calculate_metrics(y_test, y_pred)\n",
    "    metricas_modelos[nome_modelo] = metrics\n",
    "\n",
    "# Criar DataFrame com m\u00e9tricas\n",
    "df_metricas = pd.DataFrame(metricas_modelos).T\n",
    "\n",
    "print(\"\\nPerformance dos Modelos:\")\n",
    "print(\"=\" * 80)\n",
    "print(df_metricas.round(4))\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "\n",
    "# Identificar melhor modelo por m\u00e9trica\n",
    "print(\"\\nMelhores Modelos por M\u00e9trica:\")\n",
    "for metrica in df_metricas.columns:\n",
    "    if metrica in ['mae', 'rmse', 'mape']:\n",
    "        melhor = df_metricas[metrica].idxmin()\n",
    "        valor = df_metricas.loc[melhor, metrica]\n",
    "    else:\n",
    "        melhor = df_metricas[metrica].idxmax()\n",
    "        valor = df_metricas.loc[melhor, metrica]\n",
    "    print(f\"  {metrica.upper():10s}: {melhor:20s} ({valor:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar previs\u00f5es vs valores reais\n",
    "fig, axes = plt.subplots(3, 2, figsize=(16, 12))\n",
    "fig.suptitle('Compara\u00e7\u00e3o: Previs\u00f5es vs Valores Reais', fontsize=16, fontweight='bold')\n",
    "\n",
    "for idx, (nome_modelo, y_pred) in enumerate(previsoes.items()):\n",
    "    ax = axes[idx // 2, idx % 2]\n",
    "    \n",
    "    # Plot\n",
    "    ax.plot(test_data.index, y_test, 'o-', label='Real', linewidth=2, markersize=4)\n",
    "    ax.plot(test_data.index, y_pred, 's--', label='Previsto', linewidth=2, markersize=4, alpha=0.7)\n",
    "    \n",
    "    # Adicionar m\u00e9tricas no t\u00edtulo\n",
    "    rmse = metricas_modelos[nome_modelo]['rmse']\n",
    "    mape = metricas_modelos[nome_modelo]['mape']\n",
    "    ax.set_title(f\"{nome_modelo}\\nRMSE: {rmse:.3f} | MAPE: {mape:.2f}%\", \n",
    "                 fontsize=11, fontweight='bold')\n",
    "    \n",
    "    ax.set_xlabel('Data')\n",
    "    ax.set_ylabel('IDCI-VIX')\n",
    "    ax.legend(loc='best')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Remover subplot extra\n",
    "fig.delaxes(axes[2, 1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Ensemble Learning - Combina\u00e7\u00e3o de Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation.ensemble import EnsembleCombiner\n",
    "\n",
    "# Preparar previs\u00f5es como matriz\n",
    "predictions_matrix = np.column_stack([previsoes[m] for m in previsoes.keys()])\n",
    "\n",
    "# Criar ensemble com diferentes estrat\u00e9gias\n",
    "ensemble_strategies = ['simple_average', 'weighted_average', 'median']\n",
    "ensemble_results = {}\n",
    "\n",
    "for strategy in ensemble_strategies:\n",
    "    combiner = EnsembleCombiner(method=strategy)\n",
    "    combiner.fit(predictions_matrix, y_test)\n",
    "    y_ensemble = combiner.predict(predictions_matrix)\n",
    "    \n",
    "    metrics = calculate_metrics(y_test, y_ensemble)\n",
    "    ensemble_results[f\"Ensemble ({strategy})\"] = {\n",
    "        'predictions': y_ensemble,\n",
    "        'metrics': metrics\n",
    "    }\n",
    "\n",
    "# Comparar ensemble com modelos individuais\n",
    "print(\"\\nPerformance do Ensemble vs Modelos Individuais:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Adicionar m\u00e9tricas de ensemble ao DataFrame\n",
    "for name, result in ensemble_results.items():\n",
    "    df_metricas.loc[name] = result['metrics']\n",
    "\n",
    "print(df_metricas.round(4))\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "\n",
    "# Melhor modelo geral\n",
    "melhor_modelo_geral = df_metricas['rmse'].idxmin()\n",
    "print(f\"\\n\ud83c\udfc6 Melhor Modelo (menor RMSE): {melhor_modelo_geral}\")\n",
    "print(f\"   RMSE: {df_metricas.loc[melhor_modelo_geral, 'rmse']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar compara\u00e7\u00e3o de ensemble\n",
    "fig, ax = plt.subplots(figsize=(14, 7))\n",
    "\n",
    "ax.plot(test_data.index, y_test, 'o-', label='Real', linewidth=3, markersize=6, color='black')\n",
    "\n",
    "colors = ['blue', 'green', 'red']\n",
    "for idx, (name, result) in enumerate(ensemble_results.items()):\n",
    "    ax.plot(test_data.index, result['predictions'], 's--', \n",
    "            label=name, linewidth=2, markersize=5, alpha=0.7, color=colors[idx])\n",
    "\n",
    "ax.set_title('Compara\u00e7\u00e3o de Estrat\u00e9gias de Ensemble', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Data', fontsize=12)\n",
    "ax.set_ylabel('IDCI-VIX', fontsize=12)\n",
    "ax.legend(loc='best', fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. An\u00e1lise de Res\u00edduos e Diagn\u00f3sticos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# Selecionar melhor modelo para an\u00e1lise de res\u00edduos\n",
    "modelo_analise = 'ARIMA'\n",
    "residuos = y_test - previsoes[modelo_analise]\n",
    "\n",
    "# Criar figura com m\u00faltiplos diagn\u00f3sticos\n",
    "fig = plt.figure(figsize=(16, 10))\n",
    "gs = fig.add_gridspec(3, 2, hspace=0.3, wspace=0.3)\n",
    "\n",
    "# 1. Res\u00edduos ao longo do tempo\n",
    "ax1 = fig.add_subplot(gs[0, :])\n",
    "ax1.plot(test_data.index, residuos, 'o-', linewidth=2)\n",
    "ax1.axhline(y=0, color='red', linestyle='--', alpha=0.5)\n",
    "ax1.fill_between(test_data.index, -2*residuos.std(), 2*residuos.std(), alpha=0.2)\n",
    "ax1.set_title(f'Res\u00edduos do Modelo {modelo_analise}', fontsize=12, fontweight='bold')\n",
    "ax1.set_ylabel('Res\u00edduo')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Histograma dos res\u00edduos\n",
    "ax2 = fig.add_subplot(gs[1, 0])\n",
    "ax2.hist(residuos, bins=15, edgecolor='black', alpha=0.7)\n",
    "ax2.set_title('Distribui\u00e7\u00e3o dos Res\u00edduos', fontsize=11, fontweight='bold')\n",
    "ax2.set_xlabel('Res\u00edduo')\n",
    "ax2.set_ylabel('Frequ\u00eancia')\n",
    "ax2.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# 3. Q-Q Plot\n",
    "ax3 = fig.add_subplot(gs[1, 1])\n",
    "stats.probplot(residuos, dist=\"norm\", plot=ax3)\n",
    "ax3.set_title('Q-Q Plot (Normalidade)', fontsize=11, fontweight='bold')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. ACF dos res\u00edduos\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "ax4 = fig.add_subplot(gs[2, 0])\n",
    "plot_acf(residuos, lags=min(20, len(residuos)//2), ax=ax4)\n",
    "ax4.set_title('Autocorrela\u00e7\u00e3o dos Res\u00edduos', fontsize=11, fontweight='bold')\n",
    "\n",
    "# 5. Scatter: Previsto vs Real\n",
    "ax5 = fig.add_subplot(gs[2, 1])\n",
    "ax5.scatter(y_test, previsoes[modelo_analise], alpha=0.6, s=50)\n",
    "ax5.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], \n",
    "         'r--', linewidth=2, label='Linha ideal')\n",
    "ax5.set_xlabel('Valores Reais')\n",
    "ax5.set_ylabel('Valores Previstos')\n",
    "ax5.set_title('Previsto vs Real', fontsize=11, fontweight='bold')\n",
    "ax5.legend()\n",
    "ax5.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle(f'Diagn\u00f3sticos Completos - {modelo_analise}', \n",
    "             fontsize=14, fontweight='bold', y=0.995)\n",
    "plt.show()\n",
    "\n",
    "# Testes estat\u00edsticos\n",
    "print(\"\\nTestes Estat\u00edsticos dos Res\u00edduos:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Teste de normalidade (Shapiro-Wilk)\n",
    "stat_sw, p_sw = stats.shapiro(residuos)\n",
    "print(f\"Shapiro-Wilk (Normalidade): p-value = {p_sw:.4f}\")\n",
    "if p_sw > 0.05:\n",
    "    print(\"  \u2713 Res\u00edduos parecem seguir distribui\u00e7\u00e3o normal\")\n",
    "else:\n",
    "    print(\"  \u2717 Res\u00edduos n\u00e3o seguem distribui\u00e7\u00e3o normal\")\n",
    "\n",
    "# Teste de m\u00e9dia zero\n",
    "stat_t, p_t = stats.ttest_1samp(residuos, 0)\n",
    "print(f\"\\nTeste t (M\u00e9dia = 0): p-value = {p_t:.4f}\")\n",
    "if p_t > 0.05:\n",
    "    print(\"  \u2713 Res\u00edduos t\u00eam m\u00e9dia n\u00e3o significativamente diferente de zero\")\n",
    "else:\n",
    "    print(\"  \u2717 Res\u00edduos t\u00eam vi\u00e9s sistem\u00e1tico\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Conclus\u00f5es e Recomenda\u00e7\u00f5es\n",
    "\n",
    "### Principais Achados:\n",
    "\n",
    "1. **Constru\u00e7\u00e3o do IDCI-VIX**: O \u00edndice foi constru\u00eddo com sucesso usando modelo de fatores din\u00e2micos\n",
    "2. **Sele\u00e7\u00e3o de Vari\u00e1veis**: Granger causality identificou vari\u00e1veis relevantes\n",
    "3. **Performance dos Modelos**: Comparamos 5 modelos diferentes com m\u00e9tricas rigorosas\n",
    "4. **Ensemble**: A combina\u00e7\u00e3o de modelos geralmente melhora a performance\n",
    "\n",
    "### Pr\u00f3ximos Passos:\n",
    "\n",
    "- Valida\u00e7\u00e3o cruzada temporal mais robusta\n",
    "- Otimiza\u00e7\u00e3o de hiperpar\u00e2metros via grid search\n",
    "- An\u00e1lise de cen\u00e1rios (pessimista/base/otimista)\n",
    "- Implementa\u00e7\u00e3o em produ\u00e7\u00e3o com monitoramento cont\u00ednuo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}