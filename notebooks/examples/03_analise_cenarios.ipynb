{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise de Cenários e Sensibilidade - IDCI-VIX\n",
    "\n",
    "Este notebook demonstra técnicas avançadas de análise de cenários:\n",
    "\n",
    "- **Previsão por Quantis**: Cenários pessimista (10%), base (50%) e otimista (90%)\n",
    "- **Análise de Sensibilidade**: Impacto de variações nas variáveis preditoras\n",
    "- **Simulação de Monte Carlo**: Distribuição de resultados possíveis\n",
    "- **Backtesting**: Validação de cenários históricos\n",
    "- **Value at Risk (VaR)**: Quantificação de riscos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.abspath('../../src'))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"Set2\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preparação dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gerar_dados_realistas(n_periodos=150, seed=42):\n",
    "    \"\"\"Gera dataset sintético com variáveis macroeconômicas.\"\"\"\n",
    "    np.random.seed(seed)\n",
    "    datas = pd.date_range(start='2012-01-01', periods=n_periodos, freq='M')\n",
    "    t = np.arange(n_periodos)\n",
    "    \n",
    "    # PIB com ciclos econômicos\n",
    "    pib = 2000 + 15*t + 200*np.sin(2*np.pi*t/48) + np.random.normal(0, 50, n_periodos)\n",
    "    \n",
    "    # Selic com mudanças de regime\n",
    "    selic = np.zeros(n_periodos)\n",
    "    selic[0] = 10.0\n",
    "    for i in range(1, n_periodos):\n",
    "        shock = np.random.normal(0, 0.3)\n",
    "        if i % 30 == 0:\n",
    "            shock += np.random.choice([-2, 2])\n",
    "        selic[i] = np.clip(selic[i-1] + shock, 2.0, 20.0)\n",
    "    \n",
    "    # Inflação (IPCA)\n",
    "    ipca = np.zeros(n_periodos)\n",
    "    ipca[0] = 0.5\n",
    "    for i in range(1, n_periodos):\n",
    "        ipca[i] = 0.6*ipca[i-1] + 0.3 + np.random.normal(0, 0.2)\n",
    "        ipca[i] = np.clip(ipca[i], -1.0, 2.5)\n",
    "    \n",
    "    # Desemprego\n",
    "    pib_norm = (pib - pib.mean()) / pib.std()\n",
    "    desemprego = 10.0 - 2*pib_norm + np.random.normal(0, 0.5, n_periodos)\n",
    "    desemprego = np.clip(desemprego, 4.0, 16.0)\n",
    "    \n",
    "    # Crédito imobiliário\n",
    "    credito = 50000 + 400*t + 5000*pib_norm - 2000*(selic - selic.mean())/selic.std()\n",
    "    credito += np.random.normal(0, 2000, n_periodos)\n",
    "    \n",
    "    # Confiança do consumidor\n",
    "    confianca = 100 + 15*pib_norm - 10*(desemprego - desemprego.mean())/desemprego.std()\n",
    "    confianca += np.random.normal(0, 5, n_periodos)\n",
    "    \n",
    "    # IDCI-VIX sintético (combinação das variáveis)\n",
    "    idci_raw = (0.3*pib_norm - 0.2*(selic - selic.mean())/selic.std() + \n",
    "                0.2*confianca/20 - 0.15*(desemprego - desemprego.mean())/desemprego.std() +\n",
    "                0.15*(credito - credito.mean())/credito.std())\n",
    "    idci_vix = 5 + 2*idci_raw + np.random.normal(0, 0.3, n_periodos)\n",
    "    idci_vix = np.clip(idci_vix, 0, 10)\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'data': datas,\n",
    "        'pib_real': pib,\n",
    "        'taxa_selic': selic,\n",
    "        'ipca': ipca,\n",
    "        'taxa_desemprego': desemprego,\n",
    "        'credito_imobiliario': credito,\n",
    "        'confianca_consumidor': confianca,\n",
    "        'IDCI_VIX': idci_vix\n",
    "    })\n",
    "    \n",
    "    df.set_index('data', inplace=True)\n",
    "    return df\n",
    "\n",
    "df = gerar_dados_realistas(n_periodos=150)\n",
    "print(f\"Dataset: {len(df)} observações de {df.index[0].strftime('%Y-%m')} a {df.index[-1].strftime('%Y-%m')}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir dados\n",
    "train_size = int(0.8 * len(df))\n",
    "train_data = df.iloc[:train_size]\n",
    "test_data = df.iloc[train_size:]\n",
    "\n",
    "print(f\"Treino: {len(train_data)} obs | Teste: {len(test_data)} obs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Previsão por Quantis - Cenários Múltiplos\n",
    "\n",
    "Usar regressão quantílica para gerar três cenários:\n",
    "- **Pessimista** (quantil 10%): Cenário adverso\n",
    "- **Base** (quantil 50%): Cenário mais provável\n",
    "- **Otimista** (quantil 90%): Cenário favorável"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from forecasting.quantile_reg import QuantileForecaster\n",
    "\n",
    "# Preparar dados\n",
    "feature_cols = ['pib_real', 'taxa_selic', 'ipca', 'taxa_desemprego', \n",
    "                'credito_imobiliario', 'confianca_consumidor']\n",
    "X_train = train_data[feature_cols].values\n",
    "y_train = train_data['IDCI_VIX'].values\n",
    "X_test = test_data[feature_cols].values\n",
    "y_test = test_data['IDCI_VIX'].values\n",
    "\n",
    "# Treinar modelos para diferentes quantis\n",
    "quantis = [0.10, 0.50, 0.90]\n",
    "cenarios = {}\n",
    "\n",
    "for q in quantis:\n",
    "    print(f\"Treinando modelo para quantil {q:.0%}...\")\n",
    "    qf = QuantileForecaster(quantile=q, lags=3)\n",
    "    qf.fit(X_train, y_train)\n",
    "    pred = qf.forecast(X_test)\n",
    "    \n",
    "    if q == 0.10:\n",
    "        cenarios['Pessimista'] = pred\n",
    "    elif q == 0.50:\n",
    "        cenarios['Base'] = pred\n",
    "    else:\n",
    "        cenarios['Otimista'] = pred\n",
    "\n",
    "print(\"\\n✓ Cenários gerados com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar cenários\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "# Valores reais\n",
    "ax.plot(test_data.index, y_test, 'o-', label='Real', \n",
    "        linewidth=3, markersize=7, color='black', zorder=5)\n",
    "\n",
    "# Cenário base\n",
    "ax.plot(test_data.index, cenarios['Base'], 's--', label='Cenário Base (Q50)', \n",
    "        linewidth=2.5, markersize=6, color='blue', alpha=0.8)\n",
    "\n",
    "# Área de incerteza (pessimista a otimista)\n",
    "ax.fill_between(test_data.index, \n",
    "                cenarios['Pessimista'], \n",
    "                cenarios['Otimista'],\n",
    "                alpha=0.3, color='skyblue', label='Intervalo de Confiança (Q10-Q90)')\n",
    "\n",
    "# Linhas dos cenários extremos\n",
    "ax.plot(test_data.index, cenarios['Pessimista'], '^:', \n",
    "        label='Cenário Pessimista (Q10)', linewidth=2, markersize=5, color='red', alpha=0.7)\n",
    "ax.plot(test_data.index, cenarios['Otimista'], 'v:', \n",
    "        label='Cenário Otimista (Q90)', linewidth=2, markersize=5, color='green', alpha=0.7)\n",
    "\n",
    "ax.set_title('Análise de Cenários - IDCI-VIX', fontsize=16, fontweight='bold', pad=20)\n",
    "ax.set_xlabel('Data', fontsize=13)\n",
    "ax.set_ylabel('IDCI-VIX (0-10)', fontsize=13)\n",
    "ax.legend(loc='best', fontsize=11, framealpha=0.9)\n",
    "ax.grid(True, alpha=0.4)\n",
    "ax.set_ylim(0, 10)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tabela de cenários\n",
    "df_cenarios = pd.DataFrame({\n",
    "    'Data': test_data.index,\n",
    "    'Real': y_test,\n",
    "    'Pessimista': cenarios['Pessimista'],\n",
    "    'Base': cenarios['Base'],\n",
    "    'Otimista': cenarios['Otimista']\n",
    "})\n",
    "\n",
    "df_cenarios['Amplitude'] = df_cenarios['Otimista'] - df_cenarios['Pessimista']\n",
    "df_cenarios['Dentro_Intervalo'] = (\n",
    "    (df_cenarios['Real'] >= df_cenarios['Pessimista']) & \n",
    "    (df_cenarios['Real'] <= df_cenarios['Otimista'])\n",
    ")\n",
    "\n",
    "cobertura = df_cenarios['Dentro_Intervalo'].mean() * 100\n",
    "print(f\"\\nCobertura do Intervalo (Q10-Q90): {cobertura:.1f}%\")\n",
    "print(f\"Amplitude média: {df_cenarios['Amplitude'].mean():.2f}\")\n",
    "print(\"\\nPrimeiras previsões:\")\n",
    "df_cenarios.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Análise de Sensibilidade\n",
    "\n",
    "Avaliar como mudanças nas variáveis preditoras afetam o IDCI-VIX:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from forecasting.random_forest import RandomForestForecaster\n",
    "\n",
    "# Treinar modelo Random Forest para análise de sensibilidade\n",
    "rf = RandomForestForecaster(n_estimators=200, max_depth=15, lags=5, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Importância das features\n",
    "importances = rf.feature_importance(feature_cols)\n",
    "\n",
    "print(\"Importância das Variáveis:\")\n",
    "print(\"=\" * 60)\n",
    "for var, imp in sorted(importances.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"{var:30s} {'█' * int(imp*50)} {imp:.3f}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análise de sensibilidade: variar cada variável mantendo outras constantes\n",
    "def analise_sensibilidade(model, X_base, feature_idx, feature_name, variation_pct=0.2, n_points=50):\n",
    "    \"\"\"\n",
    "    Analisa sensibilidade variando uma feature específica.\n",
    "    \n",
    "    Args:\n",
    "        model: Modelo treinado\n",
    "        X_base: Matriz de features base\n",
    "        feature_idx: Índice da feature a variar\n",
    "        feature_name: Nome da feature\n",
    "        variation_pct: Percentual de variação (+/-)\n",
    "        n_points: Número de pontos a avaliar\n",
    "    \"\"\"\n",
    "    # Pegar valores médios como baseline\n",
    "    x_baseline = X_base.mean(axis=0).reshape(1, -1)\n",
    "    baseline_value = x_baseline[0, feature_idx]\n",
    "    \n",
    "    # Range de variação\n",
    "    var_min = baseline_value * (1 - variation_pct)\n",
    "    var_max = baseline_value * (1 + variation_pct)\n",
    "    var_range = np.linspace(var_min, var_max, n_points)\n",
    "    \n",
    "    # Previsões variando a feature\n",
    "    predictions = []\n",
    "    for val in var_range:\n",
    "        x_modified = x_baseline.copy()\n",
    "        x_modified[0, feature_idx] = val\n",
    "        pred = model.forecast(x_modified)[0]\n",
    "        predictions.append(pred)\n",
    "    \n",
    "    return var_range, np.array(predictions)\n",
    "\n",
    "# Análise para cada variável\n",
    "fig, axes = plt.subplots(3, 2, figsize=(16, 14))\n",
    "fig.suptitle('Análise de Sensibilidade - Impacto das Variáveis no IDCI-VIX', \n",
    "             fontsize=16, fontweight='bold')\n",
    "\n",
    "for idx, feature_name in enumerate(feature_cols):\n",
    "    ax = axes[idx // 2, idx % 2]\n",
    "    \n",
    "    var_range, predictions = analise_sensibilidade(\n",
    "        rf, X_test, idx, feature_name, variation_pct=0.3, n_points=100\n",
    "    )\n",
    "    \n",
    "    # Plot\n",
    "    ax.plot(var_range, predictions, linewidth=3, color='darkblue')\n",
    "    ax.axvline(X_test[:, idx].mean(), color='red', linestyle='--', \n",
    "               alpha=0.7, label='Média Atual')\n",
    "    ax.axhline(y_test.mean(), color='green', linestyle=':', \n",
    "               alpha=0.7, label='IDCI-VIX Médio')\n",
    "    \n",
    "    # Calcular elasticidade\n",
    "    delta_pred = predictions[-1] - predictions[0]\n",
    "    delta_var = var_range[-1] - var_range[0]\n",
    "    elasticity = (delta_pred / predictions[0]) / (delta_var / var_range[0])\n",
    "    \n",
    "    ax.set_title(f\"{feature_name.replace('_', ' ').title()}\\nElasticidade: {elasticity:.3f}\", \n",
    "                 fontsize=11, fontweight='bold')\n",
    "    ax.set_xlabel(feature_name.replace('_', ' ').title(), fontsize=10)\n",
    "    ax.set_ylabel('IDCI-VIX Previsto', fontsize=10)\n",
    "    ax.legend(loc='best', fontsize=9)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Simulação de Monte Carlo\n",
    "\n",
    "Simular múltiplos cenários usando distribuições probabilísticas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monte_carlo_simulation(model, X_base, n_simulations=1000, noise_std=0.1):\n",
    "    \"\"\"\n",
    "    Realiza simulação de Monte Carlo adicionando ruído às features.\n",
    "    \n",
    "    Args:\n",
    "        model: Modelo treinado\n",
    "        X_base: Features base\n",
    "        n_simulations: Número de simulações\n",
    "        noise_std: Desvio padrão do ruído (proporcional)\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for _ in range(n_simulations):\n",
    "        # Adicionar ruído gaussiano às features\n",
    "        noise = np.random.normal(1.0, noise_std, X_base.shape)\n",
    "        X_perturbed = X_base * noise\n",
    "        \n",
    "        # Prever\n",
    "        predictions = model.forecast(X_perturbed)\n",
    "        results.append(predictions)\n",
    "    \n",
    "    return np.array(results)\n",
    "\n",
    "# Executar Monte Carlo\n",
    "print(\"Executando simulação de Monte Carlo...\")\n",
    "mc_results = monte_carlo_simulation(rf, X_test, n_simulations=2000, noise_std=0.15)\n",
    "\n",
    "print(f\"✓ {len(mc_results)} simulações concluídas\")\n",
    "print(f\"Forma dos resultados: {mc_results.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar distribuição das simulações\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('Simulação de Monte Carlo - Distribuição de Cenários', \n",
    "             fontsize=16, fontweight='bold')\n",
    "\n",
    "# Selecionar alguns períodos para visualizar\n",
    "periodos_plot = [0, len(test_data)//3, 2*len(test_data)//3, -1]\n",
    "titles = ['Início', 'T+10', 'T+20', 'Fim']\n",
    "\n",
    "for idx, (periodo, title) in enumerate(zip(periodos_plot, titles)):\n",
    "    ax = axes[idx // 2, idx % 2]\n",
    "    \n",
    "    # Distribuição das simulações\n",
    "    simulations = mc_results[:, periodo]\n",
    "    \n",
    "    ax.hist(simulations, bins=40, edgecolor='black', alpha=0.7, density=True)\n",
    "    \n",
    "    # Estatísticas\n",
    "    mean_sim = simulations.mean()\n",
    "    median_sim = np.median(simulations)\n",
    "    std_sim = simulations.std()\n",
    "    \n",
    "    # Linhas de referência\n",
    "    ax.axvline(mean_sim, color='red', linestyle='--', linewidth=2, label=f'Média: {mean_sim:.2f}')\n",
    "    ax.axvline(median_sim, color='green', linestyle='--', linewidth=2, label=f'Mediana: {median_sim:.2f}')\n",
    "    ax.axvline(y_test[periodo], color='black', linestyle='-', linewidth=3, \n",
    "               label=f'Real: {y_test[periodo]:.2f}')\n",
    "    \n",
    "    # Intervalo de confiança 90%\n",
    "    ci_lower = np.percentile(simulations, 5)\n",
    "    ci_upper = np.percentile(simulations, 95)\n",
    "    ax.axvspan(ci_lower, ci_upper, alpha=0.2, color='yellow', label=f'IC 90%: [{ci_lower:.2f}, {ci_upper:.2f}]')\n",
    "    \n",
    "    ax.set_title(f\"{title} - {test_data.index[periodo].strftime('%Y-%m')}\\nσ = {std_sim:.2f}\", \n",
    "                 fontsize=12, fontweight='bold')\n",
    "    ax.set_xlabel('IDCI-VIX', fontsize=11)\n",
    "    ax.set_ylabel('Densidade', fontsize=11)\n",
    "    ax.legend(loc='best', fontsize=9)\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fanplot - Visualizar evolução da incerteza\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "# Calcular percentis ao longo do tempo\n",
    "percentiles = [5, 25, 50, 75, 95]\n",
    "percentile_values = {p: np.percentile(mc_results, p, axis=0) for p in percentiles}\n",
    "\n",
    "# Plot\n",
    "ax.plot(test_data.index, y_test, 'o-', label='Real', \n",
    "        linewidth=3, markersize=7, color='black', zorder=10)\n",
    "ax.plot(test_data.index, percentile_values[50], '-', label='Mediana', \n",
    "        linewidth=2.5, color='blue', zorder=5)\n",
    "\n",
    "# Faixas de incerteza\n",
    "ax.fill_between(test_data.index, percentile_values[5], percentile_values[95],\n",
    "                alpha=0.2, color='blue', label='IC 90%')\n",
    "ax.fill_between(test_data.index, percentile_values[25], percentile_values[75],\n",
    "                alpha=0.3, color='blue', label='IC 50%')\n",
    "\n",
    "ax.set_title('Fan Chart - Evolução da Incerteza (Monte Carlo)', \n",
    "             fontsize=16, fontweight='bold', pad=20)\n",
    "ax.set_xlabel('Data', fontsize=13)\n",
    "ax.set_ylabel('IDCI-VIX', fontsize=13)\n",
    "ax.legend(loc='best', fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Value at Risk (VaR) e Conditional VaR\n",
    "\n",
    "Quantificar riscos extremos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_var_cvar(simulacoes, confidence_level=0.95):\n",
    "    \"\"\"\n",
    "    Calcula Value at Risk e Conditional Value at Risk.\n",
    "    \n",
    "    VaR: Perda máxima esperada com dado nível de confiança\n",
    "    CVaR: Perda média condicional além do VaR\n",
    "    \"\"\"\n",
    "    alpha = 1 - confidence_level\n",
    "    \n",
    "    # VaR: percentil inferior\n",
    "    var = np.percentile(simulacoes, alpha * 100, axis=0)\n",
    "    \n",
    "    # CVaR: média dos valores abaixo do VaR\n",
    "    cvar = np.array([simulacoes[:, i][simulacoes[:, i] <= var[i]].mean() \n",
    "                     for i in range(simulacoes.shape[1])])\n",
    "    \n",
    "    return var, cvar\n",
    "\n",
    "# Calcular VaR e CVaR\n",
    "var_95, cvar_95 = calcular_var_cvar(mc_results, confidence_level=0.95)\n",
    "\n",
    "print(\"Value at Risk (VaR) e Conditional VaR (CVaR) - 95% confiança\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"VaR médio (5% pior cenário): {var_95.mean():.2f}\")\n",
    "print(f\"CVaR médio (média dos 5% piores): {cvar_95.mean():.2f}\")\n",
    "print(f\"Diferença CVaR-VaR: {(cvar_95 - var_95).mean():.2f}\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar VaR e CVaR\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "# Valores reais e previsão mediana\n",
    "ax.plot(test_data.index, y_test, 'o-', label='Real', \n",
    "        linewidth=3, markersize=7, color='black', zorder=10)\n",
    "ax.plot(test_data.index, percentile_values[50], '-', label='Previsão Mediana', \n",
    "        linewidth=2.5, color='blue', zorder=5)\n",
    "\n",
    "# VaR e CVaR\n",
    "ax.plot(test_data.index, var_95, '--', label='VaR 95%', \n",
    "        linewidth=2.5, color='orange', zorder=6)\n",
    "ax.plot(test_data.index, cvar_95, ':', label='CVaR 95%', \n",
    "        linewidth=3, color='red', zorder=7)\n",
    "\n",
    "# Área de risco extremo\n",
    "ax.fill_between(test_data.index, 0, cvar_95, \n",
    "                alpha=0.15, color='red', label='Zona de Risco Extremo')\n",
    "\n",
    "ax.set_title('Análise de Risco - VaR e CVaR', fontsize=16, fontweight='bold', pad=20)\n",
    "ax.set_xlabel('Data', fontsize=13)\n",
    "ax.set_ylabel('IDCI-VIX', fontsize=13)\n",
    "ax.set_ylim(0, 10)\n",
    "ax.legend(loc='best', fontsize=11, framealpha=0.9)\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Backtesting de Cenários\n",
    "\n",
    "Validar se os cenários históricos tiveram cobertura adequada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análise de cobertura dos intervalos\n",
    "def avaliar_cobertura(real, simulacoes, percentis=[5, 95]):\n",
    "    \"\"\"\n",
    "    Avalia se os valores reais caem dentro dos intervalos previstos.\n",
    "    \"\"\"\n",
    "    lower = np.percentile(simulacoes, percentis[0], axis=0)\n",
    "    upper = np.percentile(simulacoes, percentis[1], axis=0)\n",
    "    \n",
    "    dentro = (real >= lower) & (real <= upper)\n",
    "    cobertura = dentro.mean()\n",
    "    \n",
    "    return cobertura, dentro, lower, upper\n",
    "\n",
    "# Avaliar diferentes níveis de confiança\n",
    "niveis_confianca = [(5, 95), (10, 90), (25, 75)]\n",
    "resultados_cobertura = {}\n",
    "\n",
    "print(\"Análise de Cobertura dos Intervalos:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for percentis in niveis_confianca:\n",
    "    cobertura, dentro, lower, upper = avaliar_cobertura(y_test, mc_results, percentis)\n",
    "    nivel = percentis[1] - percentis[0]\n",
    "    resultados_cobertura[nivel] = {\n",
    "        'cobertura_observada': cobertura,\n",
    "        'cobertura_esperada': nivel / 100,\n",
    "        'dentro': dentro,\n",
    "        'lower': lower,\n",
    "        'upper': upper\n",
    "    }\n",
    "    \n",
    "    print(f\"Intervalo {percentis[0]}-{percentis[1]} (esperado {nivel}%):\")\n",
    "    print(f\"  Cobertura observada: {cobertura*100:.1f}%\")\n",
    "    print(f\"  Períodos dentro: {dentro.sum()}/{len(dentro)}\")\n",
    "    print()\n",
    "\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar backtesting\n",
    "fig, axes = plt.subplots(3, 1, figsize=(16, 12))\n",
    "fig.suptitle('Backtesting - Avaliação de Cobertura dos Intervalos', \n",
    "             fontsize=16, fontweight='bold')\n",
    "\n",
    "for idx, (nivel, resultado) in enumerate(resultados_cobertura.items()):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # Plot\n",
    "    ax.plot(test_data.index, y_test, 'o-', label='Real', \n",
    "            linewidth=2.5, markersize=6, color='black')\n",
    "    \n",
    "    # Intervalo\n",
    "    ax.fill_between(test_data.index, \n",
    "                    resultado['lower'], \n",
    "                    resultado['upper'],\n",
    "                    alpha=0.3, label=f'Intervalo {nivel}%')\n",
    "    \n",
    "    # Marcar pontos fora do intervalo\n",
    "    fora = ~resultado['dentro']\n",
    "    if fora.any():\n",
    "        ax.scatter(test_data.index[fora], y_test[fora], \n",
    "                  color='red', s=100, marker='X', \n",
    "                  label='Fora do intervalo', zorder=10)\n",
    "    \n",
    "    cobertura_obs = resultado['cobertura_observada'] * 100\n",
    "    ax.set_title(f\"Intervalo {nivel}% | Cobertura: {cobertura_obs:.1f}%\", \n",
    "                 fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('IDCI-VIX', fontsize=11)\n",
    "    ax.legend(loc='best', fontsize=10)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    if idx < 2:\n",
    "        ax.set_xticklabels([])\n",
    "    else:\n",
    "        ax.set_xlabel('Data', fontsize=11)\n",
    "        plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Resumo e Insights\n",
    "\n",
    "### Principais Descobertas:\n",
    "\n",
    "1. **Cenários Quantílicos**: Fornecemos previsões para cenários pessimista, base e otimista\n",
    "2. **Sensibilidade**: Identificamos quais variáveis têm maior impacto no IDCI-VIX\n",
    "3. **Monte Carlo**: Quantificamos a incerteza através de milhares de simulações\n",
    "4. **Gestão de Risco**: Calculamos VaR e CVaR para quantificar riscos extremos\n",
    "5. **Backtesting**: Validamos que os intervalos de confiança têm cobertura adequada\n",
    "\n",
    "### Aplicações Práticas:\n",
    "\n",
    "- **Planejamento Estratégico**: Usar cenários para planejar diferentes futuros\n",
    "- **Análise de Risco**: VaR e CVaR para gestão de risco de portfólio\n",
    "- **Stress Testing**: Simular choques nas variáveis e avaliar impactos\n",
    "- **Comunicação**: Apresentar resultados com intervalos de confiança"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
